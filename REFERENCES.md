# References & Acknowledgments

This project was developed by learning from various sources. Below are key references that contributed to different aspects of the work.

## Research Papers
- **A. Van Den Oord et al.** - "WAVENET: A GENERATIVE MODEL FOR RAW AUDIO."  
  *Available:* [https://arxiv.org/pdf/1609.03499](https://arxiv.org/pdf/1609.03499)

- **Y. Bengio et al.** - "A Neural Probabilistic Language Model," *Journal of Machine Learning Research*, vol. 3, pp. 1137–1155, 2003.  
  *Available:* [https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)

- **K. He, X. Zhang, S. Ren, and J. Sun** - "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification."  
  *Available:* [https://arxiv.org/pdf/1502.01852](https://arxiv.org/pdf/1502.01852)

- **S. Ioffe** - "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift," 2015.  
  *Available:* [https://arxiv.org/pdf/1502.03167](https://arxiv.org/pdf/1502.03167)

- **Y. Wu, J. Johnson** - "Rethinking ‘Batch’ in BatchNorm," Facebook AI Research.  
  *Available:* [https://arxiv.org/pdf/2105.07576](https://arxiv.org/pdf/2105.07576)

- **T. Brown et al.** - "Language Models are Few-Shot Learners," Jul. 2020.  
  *Available:* [https://arxiv.org/pdf/2005.14165](https://arxiv.org/pdf/2005.14165)

- **A. Gu and T. Dao** - "Mamba: Linear-Time Sequence Modeling with Selective State Spaces."  
  *Available:* [https://arxiv.org/pdf/2312.00752](https://arxiv.org/pdf/2312.00752)

- **A. Vaswani et al.** - "Attention Is All You Need," Jun. 2017.  
  *Available:* [https://arxiv.org/pdf/1706.03762](https://arxiv.org/pdf/1706.03762)

## YouTube Channels
- **[Andrej Karpathy - Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy)**  
  - Learned and adapted code from the following videos:  
    - [The spelled-out intro to language modeling: building makemore](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2)  
    - [Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=3)  
    - [Building makemore Part 3: Activations & Gradients, BatchNorm](https://www.youtube.com/watch?v=P6sfmUTpUmc&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=4)  
    - [Building makemore Part 4: Becoming a Backprop Ninja](https://www.youtube.com/watch?v=q8SA3rM6ckI&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=5)  
    - [Building makemore Part 5: Building a WaveNet](https://www.youtube.com/watch?v=t3YJ5hKiMQ0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=6)  
    - [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=7)  

## Blogs & Documentation
- **O. Calzone** - "An Intuitive Explanation of LSTM," Medium, Apr. 10, 2022.  
  *Available:* [https://medium.com/@ottaviocalzone/an-intuitive-explanation-of-lstm-a035eb6ab42c](https://medium.com/@ottaviocalzone/an-intuitive-explanation-of-lstm-a035eb6ab42c)

- **C. Olah** - "Understanding LSTM Networks," Colah’s Blog, Aug. 27, 2015.  
  *Available:* [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

- **Maximinusjoshus** - "The Math behind Backpropagation," Medium, Nov. 30, 2021.  
  *Available:* [https://medium.com/featurepreneur/the-mathematics-of-backpropagation-4b114fd64a63](https://medium.com/featurepreneur/the-mathematics-of-backpropagation-4b114fd64a63)

- **M. Grootendorst** - "A Visual Guide to Mamba and State Space Models," newsletter.maartengrootendorst.com.  
  *Available:* [https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state)

- **DIVE INTO DEEP LEARNING** - "Long Short Term Memory (LSTM)," d2l.ai.  
  *Available:* [https://d2l.ai/chapter_recurrent-modern/lstm.html](https://d2l.ai/chapter_recurrent-modern/lstm.html)

- **A. Karpathy** - "Neural Networks: Zero To Hero," karpathy.ai.  
  *Available:* [https://karpathy.ai/zero-to-hero.html](https://karpathy.ai/zero-to-hero.html)

- **Hugging Face** - "Mamba Model Documentation."  
  *Available:* [https://huggingface.co/docs/transformers/en/model_doc/mamba](https://huggingface.co/docs/transformers/en/model_doc/mamba)

- **S. Tripathi** - "Demystifying the CLIP Model - Sonam Tripathi - Medium," Medium, Sep. 23, 2023.
  *Available*: [https://tripathisonam.medium.com/demystifying-the-clip-model-c2c6c0999ef1](https://tripathisonam.medium.com/  demystifying-the-clip-model-c2c6c0999ef1)

- **Szymon Palucha** - "Understanding OpenAI’s CLIP model - Szymon Palucha - Medium," Medium, Feb. 24, 2024.
  *Available*: [https://medium.com/@paluchasz/understanding-openais-clip-model-6b52bade3fa3](https://medium.com/@paluchasz/  understanding-openais-clip-model-6b52bade3fa3)

- **A. Khan** - "A Beginner’s Guide to Deep Learning with MNIST Dataset," Medium, Apr. 16, 2024.
  *Available*: [https://medium.com/@azimkhan8018/a-beginners-guide-to-deep-learning-with-mnist-dataset-0894f7183344](https://medium.  com/@azimkhan8018/a-beginners-guide-to-deep-learning-with-mnist-dataset-0894f7183344)

- **A. Karpathy** - "Yes you should understand backprop," Medium, Dec. 19, 2016.
  *Available*: [https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b](https://karpathy.medium.com/  yes-you-should-understand-backprop-e2f06eab496b)

- **Hugging Face** - "Introduction to State Space Models (SSM)."
  *Available*: [https://huggingface.co/blog/lbourdois/get-on-the-ssm-train](https://huggingface.co/blog/lbourdois/  get-on-the-ssm-train)

- **OpenAI** - "ChatGPT," Openai.com, Nov. 30, 2022.  
  *Available:* [https://openai.com/index/chatgpt](https://openai.com/index/chatgpt)

- **OpenAI** - "CLIP: Connecting text and images," Openai.com, 2021.  
  *Available:* [https://openai.com/index/clip](https://openai.com/index/clip)

- **S. Poudel** - "Recurrent Neural Network (RNN) Architecture Explained," Medium, Aug. 28, 2023.  
  *Available:* [https://medium.com/@poudelsushmita878/recurrent-neural-network-rnn-architecture-explained-1d69560541ef](https://medium.com/@poudelsushmita878/recurrent-neural-network-rnn-architecture-explained-1d69560541ef)

- **A. Karpathy** - "The Unreasonable Effectiveness of Recurrent Neural Networks," karpathy.github.io, May 21, 2015.  
  *Available:* [https://karpathy.github.io/2015/05/21/rnn-effectiveness/](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)

- **A. Karpathy** - "A Recipe for Training Neural Networks," karpathy.github.io.  
  *Available:* [https://karpathy.github.io/2019/04/25/recipe/](https://karpathy.github.io/2019/04/25/recipe/)

- **Oxford Emory Math** - "Bessel’s Correction."  
  *Available:* [https://math.oxford.emory.edu/site/math117/besselCorrection/](https://math.oxford.emory.edu/site/math117/besselCorrection/)