{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted and modified from https://www.kaggle.com/code/fareselmenshawii/lstm-from-scratch/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, path: str, sequence_length: int):\n",
    "        with open(path) as f:\n",
    "            # Read the contents of the file\n",
    "            self.data = f.read()\n",
    "\n",
    "        # Find all unique characters in the text\n",
    "        chars = list(set(self.data))\n",
    "\n",
    "        # Create dictionaries to map characters to indices and vice versa\n",
    "        self.char_to_idx = {ch: i for (i, ch) in enumerate(chars)}\n",
    "        self.idx_to_char = {i: ch for (i, ch) in enumerate(chars)}\n",
    "\n",
    "        # Store the size of the text data and the size of the vocabulary\n",
    "        self.data_size = len(self.data)\n",
    "        self.vocab_size = len(chars)\n",
    "\n",
    "        # Initialize the pointer that will be used to generate sequences\n",
    "        self.pointer = 0\n",
    "\n",
    "        # Store the desired sequence length\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        input_start = self.pointer\n",
    "        input_end = self.pointer + batch_size*self.sequence_length\n",
    "\n",
    "        # Get the input sequence as a list of integers\n",
    "        inputs = [self.char_to_idx[ch] for ch in self.data[input_start:input_end]]\n",
    "\n",
    "        # One-hot encode the input sequence\n",
    "        inputs_one_hot = torch.zeros((len(inputs), self.vocab_size))\n",
    "        inputs_one_hot[torch.arange(len(inputs)), inputs] = 1\n",
    "        inputs_one_hot = inputs_one_hot.reshape(batch_size, self.sequence_length, self.vocab_size)\n",
    "        # Get the target sequence as a list of integers\n",
    "        targets = torch.tensor([self.char_to_idx[ch] for ch in self.data[input_start + 1:input_end + 1]])\n",
    "        targets = targets.reshape(batch_size, self.sequence_length)\n",
    "        # Update the pointer\n",
    "        self.pointer += 4*self.sequence_length\n",
    "\n",
    "        # Reset the pointer if the next batch would exceed the length of the text data\n",
    "        if self.pointer + batch_size*self.sequence_length + 1 >= self.data_size:\n",
    "            self.pointer = 0\n",
    "\n",
    "        return inputs_one_hot, targets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        if h0 is None or c0 is None:\n",
    "            h0 = torch.zeros(self.layer_dim, x.shape[0], self.hidden_dim)\n",
    "            c0 = torch.zeros(self.layer_dim, x.shape[0], self.hidden_dim)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out = self.fc(out)\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 3\n",
    "data_generator = DataGenerator('names.txt', sequence_length)\n",
    "print(data_generator.vocab_size)\n",
    "model = LSTMModel(input_dim=data_generator.vocab_size, hidden_dim=500, layer_dim=1, output_dim=data_generator.vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Till Now, Loss: 1.6612\n",
      "Till Now, Loss: 0.4144\n",
      "Epoch [1/4], Loss: 2.1683\n",
      "Till Now, Loss: 1.1700\n",
      "Till Now, Loss: 0.4021\n",
      "Epoch [2/4], Loss: 2.5600\n",
      "Till Now, Loss: 1.0081\n",
      "Till Now, Loss: 0.4960\n",
      "Epoch [3/4], Loss: 2.3885\n",
      "Till Now, Loss: 1.5144\n",
      "Till Now, Loss: 0.6955\n",
      "Epoch [4/4], Loss: 1.9129\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    h0, c0 = None, None\n",
    "    data_generator.pointer = 1\n",
    "    i = 0\n",
    "    while(data_generator.pointer != 0):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs, targets = data_generator.next_batch(4)\n",
    "        # print(inputs.shape)\n",
    "\n",
    "        \n",
    "        outputs, h0, c0 = model(inputs, h0, c0)\n",
    "        loss = criterion(outputs, targets[:,-1].long())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        optimizer.step()\n",
    "\n",
    "        h0 = h0.detach()\n",
    "        c0 = c0.detach()\n",
    "\n",
    "        if(i % 10000 == 0):\n",
    "            print(f'Till Now, Loss: {loss.item():.4f}')\n",
    "        i+=1\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(vocab_size, data_generator, hidden_dim, start, sequence_length, n):\n",
    "    # initialize input sequence\n",
    "    x = torch.zeros((1, sequence_length, vocab_size))\n",
    "    zero_add = torch.zeros((1, 1, vocab_size))\n",
    "    chars = [ch for ch in start]\n",
    "    idxes = []\n",
    "\n",
    "    # for i in range(len(chars)):\n",
    "    #     idx = data_generator.char_to_idx[chars[i]]\n",
    "    #     x[0, sequence_length-1, idx] = 1\n",
    "    #     x = torch.cat((x[:, 1:, :], zero_add), 1)\n",
    "    #     idxes.append(idx)\n",
    "\n",
    "    # Initialize input with the provided start sequence\n",
    "    for i, char in enumerate(chars):\n",
    "        idx = data_generator.char_to_idx[char]\n",
    "        x[0, sequence_length - len(chars) + i, idx] = 1  # Fix index shifting\n",
    "        idxes.append(idx)\n",
    "            \n",
    "    h0 = torch.zeros(1, x.shape[0], hidden_dim)\n",
    "    c0 = torch.zeros(1, x.shape[0], hidden_dim)\n",
    "    # generate new sequence of characters\n",
    "    for _ in range(n):\n",
    "        predicted, h0, c0 = model(x, h0, c0)\n",
    "        # Sample from the distribution\n",
    "        predicted = F.softmax(predicted, dim=-1)\n",
    "        # print(predicted)\n",
    "        idx = torch.multinomial(predicted.squeeze(), num_samples=1).item()\n",
    "        x = torch.cat((x[:, 1:, :], zero_add), 1)\n",
    "        x[0, sequence_length-1, idx] = 1\n",
    "        # x = torch.zeros((vocab_size, 1))\n",
    "        # x[idx] = 1\n",
    "        idxes.append(idx)\n",
    "        \n",
    "    txt = ''.join(data_generator.idx_to_char[i] for i in idxes)\n",
    "    # print(repr(txt))  # Shows the exact characters in the string\n",
    "\n",
    "    txt = txt.replace('\\n',\" | \")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joshuab | aujlan | alak | obuice | marm | maziah | naveen | zakian | zabi | zehbe | noil | mus | alashannod | michi | mons | phel | paari'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predict(data_generator.vocab_size, data_generator, 500, \"joshu\", 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
